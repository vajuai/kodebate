package org.example

import ai.koog.agents.core.agent.AIAgent
import ai.koog.prompt.dsl.prompt
import ai.koog.prompt.executor.clients.openai.OpenAIClientSettings
import ai.koog.prompt.executor.clients.openai.OpenAILLMClient
import ai.koog.prompt.executor.clients.openai.OpenAIModels
import ai.koog.prompt.executor.clients.openrouter.OpenRouterLLMClient
import ai.koog.prompt.executor.clients.openrouter.OpenRouterModels
import ai.koog.prompt.executor.llms.MultiLLMPromptExecutor
import ai.koog.prompt.executor.model.PromptExecutor
import ai.koog.prompt.llm.LLMCapability
import ai.koog.prompt.llm.LLMProvider
import ai.koog.prompt.llm.LLModel
import kotlinx.coroutines.runBlocking

/**
 * è¾©è®ºçŠ¶æ€ç®¡ç†
 */
data class DebateState(
    val topic: String,
    val totalRounds: Int,
    val currentRound: Int = 1
) {
    fun shouldContinueDebate(): Boolean = currentRound <= totalRounds
    fun nextRound(): DebateState = copy(currentRound = currentRound + 1)
}

/**
 * å†…å­˜å’Œå†å²ç®¡ç†å™¨
 */
class DebateHistoryManager(
    private val executor: PromptExecutor,
    private val topic: String,
    private val summaryModel: LLModel = OpenRouterModels.Claude3Haiku
) {
    private val fullHistory = mutableListOf<String>()
    private var summarizedHistory = "æ— å†å²è®°å½•"

    fun addTurn(speaker: String, round: Int, speech: String) {
        val turnRecord = "ç¬¬ $round è½®, $speaker: $speech"
        fullHistory.add(turnRecord)
    }

    suspend fun updateSummary() {
        println("ğŸ“ [HistoryManager] ä½¿ç”¨ ${summaryModel.id} æ¨¡å‹ç”Ÿæˆæ–°ä¸€è½®çš„æ‘˜è¦...")
        val historyToSummarize = getFullHistoryForJudge()
        val summarizerAgent = AIAgent(
            executor = executor,
            llmModel = summaryModel,
            systemPrompt = """
                ä½ æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„è¾©è®ºæ‘˜è¦å‘˜ã€‚è¯·æ ¹æ®ä»¥ä¸‹å®Œæ•´è¾©è®ºè®°å½•ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´ã€ä¸­ç«‹çš„æ‘˜è¦ã€‚
                è¿™ä¸ªæ‘˜è¦å°†ä½œä¸ºä¸‹ä¸€è½®è¾©è®ºçš„ä¸Šä¸‹æ–‡ã€‚è¯·èšç„¦æ ¸å¿ƒè®ºç‚¹å’Œäº¤é”‹ï¼Œåˆ é™¤å†—ä½™ä¿¡æ¯ã€‚
                è¾©è®ºä¸»é¢˜æ˜¯: "$topic"ã€‚
            """.trimIndent()
        )
        summarizedHistory = summarizerAgent.run(historyToSummarize)
        println("âœ… [HistoryManager] æ‘˜è¦å·²æ›´æ–°ã€‚")
    }

    fun getContextForNextTurn(): String = summarizedHistory
    fun getFullHistoryForJudge(): String = fullHistory.joinToString("\n\n")
}

fun parseDebateInput(userInput: String): DebateState {
    val parts = userInput.split(',', 'ï¼Œ')
    val topic = parts.getOrNull(0)?.trim() ?: "äººå·¥æ™ºèƒ½çš„åˆ©ä¸å¼Š"
    val rounds = parts.getOrNull(1)?.filter { it.isDigit() }?.toIntOrNull() ?: 3
    return DebateState(topic = topic, totalRounds = rounds)
}

// --- Grok æ¨¡å‹å’Œ Provider å®šä¹‰ ---
object GrokProvider : LLMProvider("grok","grok")
val grok1Model = LLModel(
    id = "grok-4",
    provider = GrokProvider,
    capabilities = listOf(LLMCapability.Tools, LLMCapability.Completion)
)

// --- DeepSeek æ¨¡å‹å’Œ Provider å®šä¹‰ ---
object DeepSeekProvider : LLMProvider("deepseek","deepseek")
val deepseekJudgeModel = LLModel(
    id = "deepseek-chat",
    provider = DeepSeekProvider,
    capabilities = listOf(LLMCapability.Tools, LLMCapability.Completion)
)

fun createDebaterAgent(
    role: String,
    topic: String,
    modelName: String,
    executor: PromptExecutor
): AIAgent<String, String> {
    val model = when (modelName.lowercase()) {
        "gpt-4o" -> OpenAIModels.Chat.GPT4o
        "grok" -> grok1Model
        else -> throw IllegalArgumentException("æœªçŸ¥çš„è¾©æ‰‹æ¨¡å‹: $modelName")
    }

    val systemPrompt = """
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„AIè¾©æ‰‹ã€‚ä½ çš„è§’è‰²æ˜¯ "$role"ã€‚
        è¾©è®ºä¸»é¢˜æ˜¯"$topic"ï¼Œä½ éœ€è¦æå‡ºå¼ºæœ‰åŠ›çš„ã€æœ‰é€»è¾‘çš„è®ºç‚¹æ¥æ”¯æŒä½ çš„ç«‹åœºã€‚
        - **ä¿æŒè§’è‰²**: ä½ çš„æ‰€æœ‰å‘è¨€éƒ½å¿…é¡»ä¸¥æ ¼å›´ç»•ä½ çš„ç«‹åœºå±•å¼€ã€‚
        - **ç»“æ„æ¸…æ™°**: ä½ çš„å‘è¨€åº”è¯¥æœ‰æ˜ç¡®çš„ç»“æ„ (ä¾‹å¦‚ï¼šå…ˆé‡ç”³æˆ‘æ–¹è§‚ç‚¹ï¼Œç„¶ååé©³å¯¹æ–¹ï¼Œæœ€åæå‡ºæ–°è®ºæ®)ã€‚
        - **æœ‰åŠ›åé©³**: ä»”ç»†åˆ†æå¯¹æ‰‹çš„è®ºç‚¹ï¼Œå¹¶æå‡ºç›´æ¥ã€æœ‰åŠ›çš„åé©³ã€‚
        - **ä¿æŒä¸“æ³¨**: åªè¾“å‡ºä½ çš„è¾©è®ºå‘è¨€ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–å¯¹è¯ã€‚
        - **å…¨éƒ¨ä½¿ç”¨ä¸­æ–‡**
    """.trimIndent()

    return AIAgent(
        executor = executor,
        llmModel = model,
        systemPrompt = systemPrompt
    )
}

fun createJudgeAgent(executor: PromptExecutor): AIAgent<String, String> {
    val systemPrompt = """
        ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œã€ç«‹åœºä¸­ç«‹çš„è¾©è®ºèµ›è£åˆ¤ã€‚
        ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®åŒæ–¹å®Œæ•´çš„ã€æœªç»å‹ç¼©çš„è¾©è®ºè®°å½•ï¼Œåšå‡ºæœ€ç»ˆçš„ã€å†³å®šæ€§çš„è¯„åˆ¤ã€‚
        ä½ çš„è¯„åˆ¤å¿…é¡»å…¬å¹³ã€é€»è¾‘ä¸¥è°¨ä¸”ç»“æ„æ¸…æ™°ï¼Œéœ€è¦åŒ…æ‹¬ï¼š
        1. å¯¹åŒæ–¹æ ¸å¿ƒçŸ›ç›¾å’Œä¸»è¦è®ºç‚¹çš„ç®€è¦å›é¡¾ã€‚
        2. å¯¹æ¯ä¸€æ–¹è®ºè¯è´¨é‡ã€é€»è¾‘è¿è´¯æ€§ã€è¯æ®æœ‰æ•ˆæ€§å’Œåé©³åŠ›åº¦çš„åˆ†æã€‚
        3. æ˜ç¡®å®£å¸ƒèƒœåˆ©æ–¹ï¼Œå¹¶æä¾›ä»¤äººä¿¡æœçš„è¯¦ç»†ç†ç”±æ¥æ”¯æŒä½ çš„è£å†³ã€‚
        **ä½ çš„å…¨éƒ¨è¾“å‡ºéƒ½å¿…é¡»æ˜¯ä¸­æ–‡ã€‚**
        **ä½ å¿…é¡»åšå‡ºæ˜ç¡®çš„è£å†³ï¼Œä¸èƒ½åˆ¤ä¸ºå¹³å±€ã€‚**
    """.trimIndent()

    return AIAgent(
        executor = executor,
        llmModel = deepseekJudgeModel, // [æ›¿æ¢] ä½¿ç”¨ DeepSeek ä½œä¸ºè£åˆ¤æ¨¡å‹
        systemPrompt = systemPrompt
    )
}

fun main() {
    System.setProperty("org.slf4j.simpleLogger.defaultLogLevel", "warn")

    println("ğŸ¯ åŠ¨æ€ AI è¾©è®ºç³»ç»Ÿ (v3.0 DeepSeek è£åˆ¤ç‰ˆ) å¯åŠ¨...")

    val openAIApiToken = System.getenv("OPENAI_API_KEY")
    val grokApiToken = System.getenv("GROK_API_KEY")
    val deepseekApiToken = System.getenv("DEEPSEEK_API_KEY") // [æ–°å¢] DeepSeek API Key
    val openRouterApiToken = System.getenv("OPENROUTER_API_KEY")

    if (openAIApiToken.isNullOrBlank() || grokApiToken.isNullOrBlank() || openRouterApiToken.isNullOrBlank() || deepseekApiToken.isNullOrBlank()) {
        println("âŒ é”™è¯¯: è¯·ç¡®ä¿ OPENAI_API_KEY, GROK_API_KEY, DEEPSEEK_API_KEY, å’Œ OPENROUTER_API_KEY ç¯å¢ƒå˜é‡å‡å·²è®¾ç½®ã€‚")
        return
    }

    // [æ–°å¢] DeepSeek å®¢æˆ·ç«¯
    val deepseekClient = OpenAILLMClient(
        apiKey = deepseekApiToken,
        settings = OpenAIClientSettings("https://api.deepseek.com")
    )

    val grokClient = OpenAILLMClient(
        apiKey = grokApiToken,
        settings = OpenAIClientSettings("https://api.x.ai")
    )

    val executor = MultiLLMPromptExecutor(
        LLMProvider.OpenAI to OpenAILLMClient(openAIApiToken),
        GrokProvider to grokClient,
        DeepSeekProvider to deepseekClient, // [æ–°å¢] æ·»åŠ  DeepSeek å®¢æˆ·ç«¯
        LLMProvider.OpenRouter to OpenRouterLLMClient(openRouterApiToken) // ç”¨äºæ‘˜è¦
    )

    println("ğŸ’¬ è¯·è¾“å…¥è¾©è®ºä¸»é¢˜å’Œè½®æ¬¡ (ä¾‹å¦‚: è¿œç¨‹å·¥ä½œå¯¹å…¬å¸æ–‡åŒ–çš„åˆ©å¼Š,3è½®):")
    print("ğŸ¤ è¯·è¾“å…¥: ")
    val userInput = readlnOrNull()?.takeIf { it.isNotBlank() } ?: "è¿œç¨‹å·¥ä½œå¯¹å…¬å¸æ–‡åŒ–çš„åˆ©å¼Š,3è½®"
    var state = parseDebateInput(userInput)
    println("\nè¾©è®ºå¼€å§‹ï¼ä¸»é¢˜ï¼š'${state.topic}'ï¼Œæ€»å…± ${state.totalRounds} è½®\n")

    // [ä¿®æ”¹] åˆ›å»º Agent æ—¶ä¼ å…¥è¾©è®ºä¸»é¢˜
    val proAgent = createDebaterAgent("æ­£æ–¹", state.topic, "gpt-4o", executor)
    val conAgent = createDebaterAgent("åæ–¹", state.topic, "grok", executor)
    val judgeAgent = createJudgeAgent(executor)

    val historyManager = DebateHistoryManager(
        executor = executor,
        topic = state.topic,
        summaryModel = OpenRouterModels.Claude3Haiku
    )

    runBlocking {
        while (state.shouldContinueDebate()) {
            println("--- ç¬¬ ${state.currentRound} è½® ---")

            val proInput = "è¾©è®ºä¸Šä¸‹æ–‡:\n${historyManager.getContextForNextTurn()}\n\nè¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œå¼€å§‹ä½ çš„å‘è¨€ã€‚"
            val proSpeech = proAgent.run(proInput)
            println("ğŸ—£ï¸ æ­£æ–¹ (GPT-4o) å‘è¨€:\n$proSpeech\n")
            historyManager.addTurn("æ­£æ–¹", state.currentRound, proSpeech)

            val conInput = "è¾©è®ºä¸Šä¸‹æ–‡:\n${historyManager.getContextForNextTurn()}\n\nè¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œå¼€å§‹ä½ çš„å‘è¨€ã€‚"
            val conSpeech = conAgent.run(conInput)
            println("ğŸ—£ï¸ åæ–¹ (Grok/${grok1Model.id}) å‘è¨€:\n$conSpeech\n")
            historyManager.addTurn("åæ–¹", state.currentRound, conSpeech)

            historyManager.updateSummary()

            state = state.nextRound()
        }

        println("\n--- è¾©è®ºç»“æŸï¼Œè¿›å…¥æœ€ç»ˆè¯„åˆ¤ç¯èŠ‚ ---")

        val finalHistory = historyManager.getFullHistoryForJudge()
        val finalJudgment = judgeAgent.run("è¿™æ˜¯å®Œæ•´çš„è¾©è®ºå†å²è®°å½•:\n\n$finalHistory")

        // [æ›¿æ¢] æ›´æ–°è£åˆ¤çš„æ‰“å°ä¿¡æ¯
        println("âš–ï¸ è£åˆ¤ (DeepSeek/${deepseekJudgeModel.id}) æœ€ç»ˆåˆ¤å†³:\n$finalJudgment")
        println("\nğŸ† AI vs AI è¾©è®ºå¤§èµ›åœ†æ»¡ç»“æŸï¼")
    }
}