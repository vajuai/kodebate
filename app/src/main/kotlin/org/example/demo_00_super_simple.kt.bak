package org.example

import ai.koog.agents.core.agent.AIAgent
import ai.koog.agents.core.tools.ToolRegistry
import ai.koog.agents.ext.agent.simpleSingleRunAgent
import ai.koog.agents.ext.tool.SayToUser
import ai.koog.agents.features.common.message.FeatureMessage
import ai.koog.agents.features.common.message.FeatureMessageProcessor
import ai.koog.agents.features.tracing.feature.Tracing
import ai.koog.prompt.executor.clients.openai.OpenAIModels
import ai.koog.prompt.executor.llms.all.simpleOpenAIExecutor
import kotlinx.coroutines.runBlocking

fun main() = runBlocking {
    val apiKey = System.getenv("OPENAI_API_KEY")

    val toolRegistry = ToolRegistry {
        tools(
            listOf(SayToUser)
        )
    }

    val agent = AIAgent(
        executor = simpleOpenAIExecutor(apiKey),
        systemPrompt = """
            You are a helpful assistant that can answer general questions.            
            Answer any user query and provide a detailed response. 
            Once you have the answer, tell it to the user
        """.trimIndent(),
        llmModel = OpenAIModels.Chat.GPT4o,
        toolRegistry = toolRegistry,
    )
    agent.run("Tell me a friendly programmers' joke about Amsterdam?")
}


// å®šä¹‰ç”¨äºç»“æ„åŒ–å“åº”çš„æ•°æ®ç±»
@Serializable
data class JokeSelection(
    val index: Int,
    val reason: String
)

val strategy = strategy("best-joke") {
    // Define nodes for different LLM models
    val nodeOpenAI by node<String, String> { topic ->
        println("ğŸ¤– OpenAI GPT-4.1 æ­£åœ¨ç”Ÿæˆç¬‘è¯...")
        llm.writeSession {
            model = OpenAIModels.Chat.GPT4_1
            updatePrompt {
                system("You are a comedian. Generate a funny joke about the given topic.straight one output, no need to compare, pick and reasoning")
                user("Tell me a joke about $topic.")
            }
            val response = requestLLMWithoutTools()
            val joke = response.content
            println("âœ… OpenAI å®Œæˆ: $joke")
            joke
        }
    }

    val nodeClaudeHaiku by node<String, String> { topic ->
        println("ğŸ¤– Claude 3 Haiku æ­£åœ¨ç”Ÿæˆç¬‘è¯...")
        llm.writeSession {
            model = OpenRouterModels.Claude3Haiku
            updatePrompt {
                system("You are a comedian. Generate a funny joke about the given topic.straight one output, no need to compare, pick and reasoning")
                user("Tell me a joke about $topic.")
            }
            val response = requestLLMWithoutTools()
            val joke = response.content
            println("âœ… Claude å®Œæˆ: $joke")
            joke
        }
    }

    val nodeGeminiFlash by node<String, String> { topic ->
        println("ğŸ¤– Gemini 2.0 Flash æ­£åœ¨ç”Ÿæˆç¬‘è¯...")
        llm.writeSession {
            model = GoogleModels.Gemini2_0Flash
            updatePrompt {
                system("You are a comedian. Generate a funny joke about the given topic. straight one output, no need to compare, pick and reasoning")
                user("Tell me a joke about $topic.")
            }
            val response = requestLLMWithoutTools()
            val joke = response.content
            println("âœ… Gemini å®Œæˆ: $joke")
            joke
        }
    }

    // Execute joke generation in parallel and select the best joke
    val nodeGenerateBestJoke by parallel(
        nodeOpenAI, nodeClaudeHaiku, nodeGeminiFlash,
    ) {
        selectByIndex { jokes ->
            println("\nğŸ¯ æ‰€æœ‰æ¨¡å‹ç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨é€‰æ‹©æœ€ä½³ç¬‘è¯...")
            println("ğŸ“‹ ç”Ÿæˆçš„ç¬‘è¯:")
            jokes.forEachIndexed { index, joke ->
                println("   ${index + 1}. $joke")
            }

            // Another LLM (e.g., GPT4o) would find the funniest joke:
            llm.writeSession {
                model = OpenAIModels.Chat.GPT4o
                updatePrompt {
                    prompt("best-joke-selector") {
                        system("You are a comedy critic. Select the best joke from the provided options.")
                        user(
                            """
                            Here are three jokes about the same topic:

                            ${jokes.mapIndexed { index, joke -> "Joke ${index + 1}:\n$joke" }.joinToString("\n\n")}

                            Select the best joke by providing the index (1, 2, or 3) and explain why it's the best.
                            Respond with a JSON object containing:
                            - index: the 1-based index of the best joke (1, 2, or 3)
                            - reason: explanation of why this joke is the best
                            """.trimIndent()
                        )
                    }
                }

                val response = requestLLMStructured(JsonStructuredData.createJsonStructure<JokeSelection>())
                val bestJoke = response.getOrNull()?.structure
                val selectedIndex = (bestJoke?.index ?: 1) - 1

                println("ğŸ† GPT-4o é€‰æ‹©äº†ç¬¬ ${bestJoke?.index} ä¸ªç¬‘è¯")
                println("ğŸ“ ç†ç”±: ${bestJoke?.reason}")
                println("ğŸ‰ æœ€ç»ˆé€‰æ‹©: ${jokes[selectedIndex]}")

                // è½¬æ¢ä¸º0-basedç´¢å¼•
                selectedIndex
            }
        }
    }

    // Connect the nodes
    nodeStart then nodeGenerateBestJoke then nodeFinish
}









