package org.example

import ai.koog.agents.core.agent.AIAgent
import ai.koog.agents.core.dsl.builder.forwardTo
import ai.koog.agents.core.dsl.builder.strategy
import ai.koog.agents.core.dsl.extension.nodeExecuteTool
import ai.koog.agents.core.dsl.extension.nodeLLMRequest
import ai.koog.agents.core.dsl.extension.nodeLLMSendToolResult
import ai.koog.agents.core.dsl.extension.onAssistantMessage
import ai.koog.agents.core.dsl.extension.onToolCall
import ai.koog.agents.core.tools.ToolRegistry
import ai.koog.prompt.dsl.prompt
import ai.koog.prompt.executor.clients.google.GoogleLLMClient
import ai.koog.prompt.executor.clients.google.GoogleModels
import ai.koog.prompt.executor.clients.openai.OpenAILLMClient
import ai.koog.prompt.executor.clients.openai.OpenAIModels
import ai.koog.prompt.executor.clients.openrouter.OpenRouterLLMClient
import ai.koog.prompt.executor.clients.openrouter.OpenRouterModels
import ai.koog.prompt.executor.llms.MultiLLMPromptExecutor
import ai.koog.prompt.llm.LLMProvider
import ai.koog.prompt.structure.json.JsonStructuredData
import kotlinx.serialization.Serializable


// å®šä¹‰ç”¨äºç»“æ„åŒ–å“åº”çš„æ•°æ®ç±»
@Serializable
data class JokeSelection(
    val index: Int,
    val reason: String
)

// ä¿®å¤åçš„ç¬‘è¯ç”Ÿæˆç­–ç•¥
val jokeStrategy = strategy("best-joke") {
    // Define nodes for different LLM models
    val nodeOpenAI by node<String, String> { topic ->
        println("ğŸ¤– [JokeAgent] OpenAI GPT-4.1 æ­£åœ¨ç”Ÿæˆç¬‘è¯...")
        llm.writeSession {
            model = OpenAIModels.Chat.GPT4_1
            updatePrompt {
                system("You are a comedian. Generate a funny joke about the given topic. Provide only the joke, no explanations.")
                user("Tell me a joke about $topic.")
            }
            val response = requestLLMWithoutTools()
            val joke = response.content
            println("âœ… [JokeAgent] OpenAI å®Œæˆ: $joke")
            joke
        }
    }

    val nodeClaudeHaiku by node<String, String> { topic ->
        println("ğŸ¤– [JokeAgent] Claude 3 Haiku æ­£åœ¨ç”Ÿæˆç¬‘è¯...")
        llm.writeSession {
            model = OpenRouterModels.Claude3Haiku
            updatePrompt {
                system("You are a comedian. Generate a funny joke about the given topic. Provide only the joke, no explanations.")
                user("Tell me a joke about $topic.")
            }
            val response = requestLLMWithoutTools()
            val joke = response.content
            println("âœ… [JokeAgent] Claude å®Œæˆ: $joke")
            joke
        }
    }

    val nodeGeminiFlash by node<String, String> { topic ->
        println("ğŸ¤– [JokeAgent] Gemini 2.0 Flash æ­£åœ¨ç”Ÿæˆç¬‘è¯...")
        llm.writeSession {
            model = GoogleModels.Gemini2_0Flash
            updatePrompt {
                system("You are a comedian. Generate a funny joke about the given topic. Provide only the joke, no explanations.")
                user("Tell me a joke about $topic.")
            }
            val response = requestLLMWithoutTools()
            val joke = response.content
            println("âœ… [JokeAgent] Gemini å®Œæˆ: $joke")
            joke
        }
    }

    // Execute joke generation in parallel and select the best joke
    val nodeGenerateBestJoke by parallel(
        nodeOpenAI, nodeClaudeHaiku, nodeGeminiFlash,
    ) {
        selectByIndex { jokes ->
            println("\nğŸ¯ [JokeAgent] æ‰€æœ‰æ¨¡å‹ç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨é€‰æ‹©æœ€ä½³ç¬‘è¯...")
            println("ğŸ“‹ [JokeAgent] ç”Ÿæˆçš„ç¬‘è¯:")
            jokes.forEachIndexed { index, joke ->
                println("   ${index + 1}. $joke")
            }

            // Another LLM (e.g., GPT4o) would find the funniest joke:
            try {
                llm.writeSession {
                    model = OpenAIModels.Chat.GPT4o
                    updatePrompt {
                        prompt("best-joke-selector") {
                            system("You are a comedy critic. Select the best joke from the provided options.")
                            user(
                                """
                                Here are three jokes about the same topic:

                                ${jokes.mapIndexed { index, joke -> "Joke ${index + 1}:\n$joke" }.joinToString("\n\n")}

                                Select the best joke by providing the index (1, 2, or 3) and explain why it's the best.
                                Respond with a JSON object containing:
                                - index: the 1-based index of the best joke (1, 2, or 3)
                                - reason: explanation of why this joke is the best
                                
                                Make sure the index is between 1 and 3 inclusive.
                                """.trimIndent()
                            )
                        }
                    }

                    val response = requestLLMStructured(JsonStructuredData.createJsonStructure<JokeSelection>())
                    val bestJoke = response.getOrNull()?.structure

                    // ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    val validIndex = when {
                        bestJoke?.index == null -> 1
                        bestJoke.index < 1 -> 1
                        bestJoke.index > 3 -> 3
                        else -> bestJoke.index
                    }

                    val selectedIndex = validIndex - 1 // è½¬æ¢ä¸º0-basedç´¢å¼•

                    println("ğŸ† [JokeAgent] GPT-4o é€‰æ‹©äº†ç¬¬ $validIndex ä¸ªç¬‘è¯")
                    println("ğŸ“ [JokeAgent] ç†ç”±: ${bestJoke?.reason ?: "Default selection"}")
                    println("ğŸ‰ [JokeAgent] æœ€ç»ˆé€‰æ‹©: ${jokes[selectedIndex]}")

                    selectedIndex
                }
            } catch (e: Exception) {
                println("âš ï¸ [JokeAgent] é€‰æ‹©è¿‡ç¨‹å‡ºé”™ï¼Œé»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªç¬‘è¯: ${e.message}")
                0 // é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªç¬‘è¯
            }
        }
    }

    // Connect the nodes
    nodeStart then nodeGenerateBestJoke then nodeFinish
}

// åˆ›å»º jokeAgent çš„å·¥å‚å‡½æ•°ï¼ˆä½¿ç”¨ String ä½œä¸ºè¾“å…¥è¾“å‡ºç±»å‹ï¼‰
fun createJokeAgent(): AIAgent<String, String> {
    val openAIApiToken = System.getenv("OPENAI_API_KEY") ?: error("OPENAI_API_KEY environment variable not set")
    val openRouterApiToken = System.getenv("OPENROUTER_API_KEY") ?: error("OPENROUTER_API_KEY environment variable not set")
    val googleApiToken = System.getenv("GEMINI_API_KEY") ?: error("GEMINI_API_KEY environment variable not set")

    val openAIClient = OpenAILLMClient(openAIApiToken)
    val openRouterClient = OpenRouterLLMClient(openRouterApiToken)
    val googleClient = GoogleLLMClient(googleApiToken)

    val multiExecutor = MultiLLMPromptExecutor(
        LLMProvider.OpenAI to openAIClient,
        LLMProvider.OpenRouter to openRouterClient,
        LLMProvider.Google to googleClient
    )

    val toolRegistry = ToolRegistry {
        // ç©ºçš„å·¥å…·æ³¨å†Œè¡¨
    }

    return AIAgent(
        executor = multiExecutor,
        systemPrompt = """
            You are a comedy assistant that generates and selects the best jokes.
            You will be given a topic and you need to find the funniest joke about that topic.
            Use multiple AI models to generate different jokes and then select the best one.
            Return only the selected joke, nothing else.
        """.trimIndent(),
        llmModel = OpenAIModels.Chat.GPT4_1,
        toolRegistry = toolRegistry,
        strategy = jokeStrategy, // ä½¿ç”¨ä¿®å¤åçš„ç­–ç•¥
    )
}

// ä¸» Agent çš„ç­–ç•¥ - ä¿®æ”¹ä¸ºä¸å…è®¸ç›´æ¥å›å¤
val chatStrategy = strategy("Multi-turn Chat") {
    val nodeAnalyzeInput by nodeLLMRequest()
    val nodeExecuteTool by nodeExecuteTool()
    val nodeSendToolResult by nodeLLMSendToolResult()

    // è¿æ¥èŠ‚ç‚¹ - ç§»é™¤ç›´æ¥å›å¤çš„è¾¹
    edge(nodeStart forwardTo nodeAnalyzeInput)
    // ç§»é™¤è¿™æ¡è¾¹ï¼Œå¼ºåˆ¶ä½¿ç”¨å·¥å…·
    // edge(nodeAnalyzeInput forwardTo nodeFinish onAssistantMessage { true })

    // åªå…è®¸å·¥å…·è°ƒç”¨
    edge(nodeAnalyzeInput forwardTo nodeExecuteTool onToolCall { true })
    edge(nodeExecuteTool forwardTo nodeSendToolResult)
    edge(nodeSendToolResult forwardTo nodeFinish onAssistantMessage { true })
    edge(nodeSendToolResult forwardTo nodeExecuteTool onToolCall { true })
}

